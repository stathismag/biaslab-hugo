+++
title = "MSc graduation project: Solving the Cocktail Party problem with Intelligent Autonomous Agents"
date = "2017-08-24T15:50:58+02:00"

description = "In this project, you are challenged to design an agent that learns to solve the cocktail party problem through on-the-spot interactions with a (human) listener."
external_link = ""
vacancy_id = "cocktail-party"
+++


## Context

{{< figure src="/img/biaslab-logo.png" title="BIASlab logo" class="right-inline" width="200px" >}}

**BIASlab** (Fig.1, <http://biaslab.org>, FLUX-7.060) is
a subgroup of the Signal Processing Systems (SPS) that aims to develop
**Intelligent Autonomous Agents** (IA). These agents interact with their
environment through their sensors and actuators in order to learn
purposeful behavior, e.g., to navigate, play soccer or they may learn to
decode speech signals under bad acoustic conditions. Our research
projects are inspired by the latest insights from machine learning,
computational neuroscience and signal processing.

## Project Description

{{< figure src="/img/proposals/cocktail-party.jpeg" title="Cocktail party" class="left-inline" width="200px" >}}

In this project, you are challenged to design **an agent that learns to solve
the cocktail party problem** through on-the-spot interactions with a (human)
listener. {{< figure src="/img/proposals/IA-loop.png" title="Intelligent agent"
class="right-inline" width="300px" >}} The cocktail party problem refers to the
issue of not being able to understand your conversation partner in the presence
of many simultaneously competing voices (Fig.2). The learning protocol is
displayed in Fig.3. A listener wears earbuds that are capable to process audio
signals in real-time (like hearing aids). In response to a detected problem, the
agent proposes the most promising alternative parameter settings for the audio
algorithm (the TRY step). Next, the new audio algorithm is executed in the ear
buds and evaluated by the listener (EXECUTE and EVALUATE steps). Based on the
listenerâ€™s appraisal, the agent should now update its model of the world (LEARN
step). This design loop repeats in real-time until the listener indicates that
the problem has been solved.


This project will get you involved with the latest **artificial
intelligence** methods, since the agent needs to (1) learn from each
interaction and (2) be smart about selecting the most promising
algorithm candidates. It will also give you an opportunity to learn
about how biological brains solve real-time design issues.

## Timing

Start date: the project is available from **September 2017** (or any time thereafter).

Duration: 9 months (fte).

## Financial Support

{{< figure src="/img/proposals/GN-logo.png" class="left-inline" width="100px" >}}

The audio solutions company GN (<http://www.gn.com/>) may financially support strong candidates (qualifications to be discussed with prof. de Vries) by a **GN scholarship**.

## Contact

For more information about this project, please contact Prof. Bert de
Vries (<bert.de.vries@tue.nl>). Also, feel free to make an appointment
to discuss alternative projects with intelligent autonomous agents that
you might be interested in.
